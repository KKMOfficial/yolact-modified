{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rnl4v6v3Pjul"
      },
      "source": [
        "#### Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nMaIBvqp5hSB"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install roboflow\n",
        "import zipfile\n",
        "\n",
        "import os, requests\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"yX1nJyVNr91CZv1vcBAf\")\n",
        "project = rf.workspace(\"minemy\").project(\"shoga-segmentation-combined-14030118\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"coco\")\n",
        "\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uQR5VlGq6Vr5"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone https://github.com/KKMOfficial/yolact-modified.git\n",
        "%cd yolact-modified"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "91v9ZlmlBn5I"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!activate yolact-env\n",
        "!pip install opencv-python\n",
        "!pip install pycocotools\n",
        "!pip install torch torchvision torchaudio\n",
        "!conda install -c conda-forge tensorboard\n",
        "!pip install numpy==1.21.6\n",
        "!pip install matplotlib==3.4.0\n",
        "!pip install ipykernel\n",
        "!pip install wget\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VvVeMcyruLBn",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title source code modifications\n",
        "# line 131\n",
        "# shoga_dataset = dataset_base.copy({\n",
        "#   'name': 'Shoga_Dataset',\n",
        "#   'train_images':'/content/shoga-segmentation-combined-14030118-2/train',\n",
        "#   'train_info':'/content/shoga-segmentation-combined-14030118-2/train/_annotations.coco.json',\n",
        "#   'valid_images': '/content/shoga-segmentation-combined-14030118-2/valid',\n",
        "#   'valid_info':   '/content/shoga-segmentation-combined-14030118-2/valid/_annotations.coco.json',\n",
        "#   'class_names': ('bottle'),\n",
        "#   'label_map': { 1:  1 },\n",
        "# })\n",
        "# line 664\n",
        "# yolact_resnet101_bottle_config = coco_base_config.copy({\n",
        "#   'name': \"bottle_detection\",\n",
        "#   'dataset': shoga_dataset,\n",
        "#   'num_classes': len(shoga_dataset.class_names) + 1,\n",
        "# })\n",
        "# make only one class bottle in the dataset file\n",
        "# backbone.py : 143: state_dict = torch.load(path, map_location=\"cuda:0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9dzjT-qnGlob",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title downlaod backbone networks\n",
        "import os, requests, zipfile\n",
        "import wget\n",
        "\n",
        "def download_file(url, dest_dir, name):\n",
        "  os.makedirs(dest_dir, exist_ok=True)\n",
        "  wget.download(url,out = f\"{dest_dir}{name}\")\n",
        "\n",
        "\n",
        "\n",
        "darknet_url = 'https://drive.usercontent.google.com/download?id=1tvqFPd4bJtakOlmn-uIA492g2qurRChj&export=download&authuser=0&confirm=t&uuid=ab9c794e-700e-4d43-9dbf-a6a188005cad&at=APZUnTXB4dxsThsKb_eEtGNW_j1F%3A1721465302564'\n",
        "resnet_url  = \"https://drive.usercontent.google.com/download?id=17Y431j4sagFpSReuPNoFcj9h7azDTZFf&export=download&authuser=0&confirm=t&uuid=91c570f0-0155-418c-8149-f68579cb7dba&at=APZUnTU7DDgtr1BiDTit8v7e1Wxn%3A1721478488916\"\n",
        "resnet50_url= \"https://drive.usercontent.google.com/download?id=1Jy3yCdbatgXa5YYIdTCRrSV0S9V5g1rn&export=download&authuser=0\"\n",
        "dataset_url = \"https://drive.usercontent.google.com/download?id=1PcJ8uwd6OGBG3w97zyH5KoxPeaSUd7k5&export=download&authuser=0&confirm=t&uuid=ce9e234a-2d81-4c33-b5f2-dc157128e6c7&at=APZUnTXbYqAFBbcNVZ6KlnBtVIY8:1721600907146\"\n",
        "dest_dir    = '/content/yolact-modified/weights/'\n",
        "# file name : resnet101_reducedfc.pth\n",
        "# file name 2 : darknet53.pth\n",
        "# resnet50 : resnet50-19c8e357.pth\n",
        "\n",
        "download_file(resnet50_url, dest_dir, \"resnet50-19c8e357.pth\")\n",
        "download_file(resnet_url, dest_dir, \"resnet101_reducedfc.pth\")\n",
        "download_file(darknet_url, dest_dir, \"darknet53.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rstrHAORPjuq"
      },
      "source": [
        "#### Train Network"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %load_ext tensorboard\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir runs --samples_per_plugin \"images=10000\""
      ],
      "metadata": {
        "id": "HE5K3NvAh5z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yZ2_p4c3E2ps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44c15886-20ba-43c2-e323-226eb3383a8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolact-modified\n",
            "\n",
            "EnvironmentNameNotFound: Could not find conda environment: yolact-env\n",
            "You can list all discoverable environments with `conda info --envs`.\n",
            "\n",
            "\n",
            "/usr/local/lib/python3.10/site-packages/torch/__init__.py:955: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:432.)\n",
            "  _C._set_default_tensor_type(t)\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "/usr/local/lib/python3.10/site-packages/torch/jit/_recursive.py:314: UserWarning: 'downsample_layers' was found in ScriptModule constants,  but it is a non-constant submodule. Consider removing it.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/site-packages/torch/jit/_recursive.py:314: UserWarning: 'pred_layers' was found in ScriptModule constants,  but it is a non-constant submodule. Consider removing it.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/site-packages/torch/jit/_recursive.py:314: UserWarning: 'lat_layers' was found in ScriptModule constants,  but it is a non-constant submodule. Consider removing it.\n",
            "  warnings.warn(\n",
            "Network Structure\n",
            "Yolact(\n",
            "  (backbone): ResNetBackbone(\n",
            "    (layers): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (3): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (4): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (5): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): Bottleneck(\n",
            "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "          (downsample): Sequential(\n",
            "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (1): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "        (2): Bottleneck(\n",
            "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (relu): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (proto_net): Sequential(\n",
            "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): InterpolateModule()\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            "  (fpn): FPN(\n",
            "    (lat_layers): RecursiveScriptModule(\n",
            "      original_name=ModuleList\n",
            "      (0): RecursiveScriptModule(original_name=Conv2d)\n",
            "      (1): RecursiveScriptModule(original_name=Conv2d)\n",
            "      (2): RecursiveScriptModule(original_name=Conv2d)\n",
            "    )\n",
            "    (pred_layers): RecursiveScriptModule(\n",
            "      original_name=ModuleList\n",
            "      (0): RecursiveScriptModule(original_name=Conv2d)\n",
            "      (1): RecursiveScriptModule(original_name=Conv2d)\n",
            "      (2): RecursiveScriptModule(original_name=Conv2d)\n",
            "    )\n",
            "    (downsample_layers): RecursiveScriptModule(\n",
            "      original_name=ModuleList\n",
            "      (0): RecursiveScriptModule(original_name=Conv2d)\n",
            "      (1): RecursiveScriptModule(original_name=Conv2d)\n",
            "    )\n",
            "  )\n",
            "  (prediction_layers): ModuleList(\n",
            "    (0): PredictionModule(\n",
            "      (upfeature): Sequential(\n",
            "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (bbox_layer): Conv2d(256, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conf_layer): Conv2d(256, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (mask_layer): Conv2d(256, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    )\n",
            "    (1-4): 4 x PredictionModule()\n",
            "  )\n",
            "  (semantic_seg_conv): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n",
            "Initializing weights...\n",
            "/content/yolact-modified/backbone.py:143: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(path, map_location=\"cuda:0\")\n",
            "Optimizer Object\n",
            "SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0.0005\n",
            ")\n",
            "Learning Rate=0.001\n",
            "Momentum=0.9\n",
            "Weight Decay=0.0005\n",
            "Criterion Informatin\n",
            "MultiBoxLoss()\n",
            "/usr/local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Dataloader Informaton\n",
            "<torch.utils.data.dataloader.DataLoader object at 0x7bfabfc5dd20>\n",
            "Begin training!\n",
            "Number Of Epochs=27587\n",
            "\n",
            "0it [00:00, ?it/s][  0]       0 || B: 4.707 | C: 17.431 | M: 4.858 | S: 4.947 | T: 31.943 || ETA: 173 days, 14:35:42 || timer: 18.750\n",
            "10it [01:22,  7.22s/it][  0]      10 || B: 4.270 | C: 11.087 | M: 3.904 | S: 3.585 | T: 22.847 || ETA: 76 days, 5:33:49 || timer: 8.248\n",
            "20it [02:34,  7.24s/it][  0]      20 || B: 3.791 | C: 8.239 | M: 3.422 | S: 2.532 | T: 17.984 || ETA: 71 days, 7:11:47 || timer: 7.252\n",
            "29it [03:36,  7.47s/it]\n",
            "1it [00:12, 12.75s/it][  1]      30 || B: 3.443 | C: 6.602 | M: 3.046 | S: 1.927 | T: 15.018 || ETA: 70 days, 17:42:39 || timer: 7.021\n",
            "11it [01:18,  6.48s/it][  1]      40 || B: 3.122 | C: 5.479 | M: 2.642 | S: 1.540 | T: 12.783 || ETA: 68 days, 3:24:05 || timer: 6.461\n",
            "21it [02:23,  6.53s/it][  1]      50 || B: 2.866 | C: 4.716 | M: 2.319 | S: 1.281 | T: 11.183 || ETA: 66 days, 12:42:18 || timer: 6.166\n",
            "29it [03:11,  6.61s/it]\n",
            "2it [00:16,  7.60s/it][  2]      60 || B: 2.680 | C: 4.134 | M: 2.080 | S: 1.096 | T: 9.990 || ETA: 65 days, 15:41:30 || timer: 7.443\n",
            "12it [01:18,  6.24s/it][  2]      70 || B: 2.505 | C: 3.689 | M: 1.889 | S: 0.958 | T: 9.041 || ETA: 64 days, 10:01:54 || timer: 6.153\n",
            "22it [02:18,  6.05s/it][  2]      80 || B: 2.336 | C: 3.358 | M: 1.724 | S: 0.851 | T: 8.269 || ETA: 63 days, 6:39:49 || timer: 5.786\n",
            "29it [02:58,  6.14s/it]\n",
            "\n",
            "Computing validation mAP (this may take a while)...\n",
            "\n",
            "\n",
            "Calculating mAP...\n",
            "\n",
            "       |  all  |  .50  |  .55  |  .60  |  .65  |  .70  |  .75  |  .80  |  .85  |  .90  |  .95  |\n",
            "-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
            "   box |  8.43 | 14.05 | 13.64 | 13.33 | 12.68 | 11.41 |  9.83 |  6.33 |  2.46 |  0.59 |  0.03 |\n",
            "  mask | 11.25 | 15.14 | 14.95 | 14.55 | 14.25 | 13.85 | 13.46 | 12.17 |  8.99 |  4.73 |  0.40 |\n",
            "-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
            "\n",
            "3it [00:23,  7.22s/it][  3]      90 || B: 2.193 | C: 3.065 | M: 1.588 | S: 0.766 | T: 7.612 || ETA: 65 days, 0:37:31 || timer: 5.372\n",
            "13it [01:19,  5.58s/it][  3]     100 || B: 2.055 | C: 2.687 | M: 1.447 | S: 0.654 | T: 6.843 || ETA: 63 days, 20:08:05 || timer: 6.161\n",
            "23it [02:16,  5.29s/it][  3]     110 || B: 1.730 | C: 1.704 | M: 1.110 | S: 0.316 | T: 4.859 || ETA: 62 days, 20:23:51 || timer: 6.753\n",
            "29it [02:49,  5.83s/it]\n",
            "4it [00:25,  5.90s/it][  4]     120 || B: 1.490 | C: 1.242 | M: 0.864 | S: 0.184 | T: 3.780 || ETA: 62 days, 2:43:59 || timer: 6.324\n",
            "14it [01:23,  5.68s/it][  4]     130 || B: 1.299 | C: 0.987 | M: 0.682 | S: 0.124 | T: 3.092 || ETA: 61 days, 12:45:21 || timer: 7.026\n",
            "24it [02:23,  5.70s/it][  4]     140 || B: 1.161 | C: 0.840 | M: 0.577 | S: 0.094 | T: 2.672 || ETA: 61 days, 1:22:22 || timer: 6.619\n",
            "29it [02:51,  5.91s/it]\n",
            "\n",
            "Computing validation mAP (this may take a while)...\n",
            "\n",
            "\n",
            "Calculating mAP...\n",
            "\n",
            "       |  all  |  .50  |  .55  |  .60  |  .65  |  .70  |  .75  |  .80  |  .85  |  .90  |  .95  |\n",
            "-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
            "   box | 10.00 | 15.48 | 15.45 | 15.13 | 14.27 | 13.61 | 12.68 |  8.81 |  3.70 |  0.79 |  0.04 |\n",
            "  mask | 13.45 | 15.83 | 15.72 | 15.65 | 15.60 | 15.35 | 15.18 | 14.66 | 13.62 | 10.58 |  2.33 |\n",
            "-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
            "\n",
            "5it [00:33,  6.18s/it][  5]     150 || B: 1.040 | C: 0.721 | M: 0.512 | S: 0.077 | T: 2.350 || ETA: 62 days, 2:26:23 || timer: 6.945\n",
            "15it [01:32,  5.83s/it][  5]     160 || B: 0.916 | C: 0.641 | M: 0.463 | S: 0.066 | T: 2.086 || ETA: 61 days, 15:03:07 || timer: 6.357\n",
            "25it [02:30,  5.51s/it][  5]     170 || B: 0.833 | C: 0.580 | M: 0.431 | S: 0.058 | T: 1.902 || ETA: 61 days, 2:14:53 || timer: 4.767\n",
            "29it [02:52,  5.96s/it]\n",
            "6it [00:38,  5.89s/it][  6]     180 || B: 0.769 | C: 0.509 | M: 0.408 | S: 0.053 | T: 1.739 || ETA: 60 days, 22:10:54 || timer: 7.042\n",
            "16it [01:36,  5.70s/it][  6]     190 || B: 0.722 | C: 0.473 | M: 0.388 | S: 0.049 | T: 1.632 || ETA: 60 days, 13:50:12 || timer: 7.403\n",
            "26it [02:33,  5.56s/it][  6]     200 || B: 0.658 | C: 0.426 | M: 0.364 | S: 0.045 | T: 1.492 || ETA: 60 days, 2:36:52 || timer: 5.164\n",
            "29it [02:49,  5.86s/it]\n",
            "\n",
            "Computing validation mAP (this may take a while)...\n",
            "\n",
            "\n",
            "Calculating mAP...\n",
            "\n",
            "       |  all  |  .50  |  .55  |  .60  |  .65  |  .70  |  .75  |  .80  |  .85  |  .90  |  .95  |\n",
            "-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
            "   box | 10.92 | 15.97 | 15.97 | 15.89 | 15.59 | 15.18 | 14.27 | 10.77 |  5.05 |  0.54 |  0.00 |\n",
            "  mask | 14.65 | 16.21 | 16.21 | 16.17 | 16.13 | 15.94 | 15.78 | 15.40 | 15.08 | 13.51 |  6.10 |\n",
            "-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
            "\n",
            "7it [00:44,  6.17s/it][  7]     210 || B: 0.606 | C: 0.395 | M: 0.344 | S: 0.042 | T: 1.387 || ETA: 60 days, 20:11:39 || timer: 5.055\n",
            "17it [01:43,  5.95s/it][  7]     220 || B: 0.565 | C: 0.370 | M: 0.324 | S: 0.040 | T: 1.299 || ETA: 60 days, 13:33:44 || timer: 4.999\n",
            "27it [02:39,  5.55s/it][  7]     230 || B: 0.543 | C: 0.333 | M: 0.305 | S: 0.037 | T: 1.219 || ETA: 60 days, 4:24:11 || timer: 5.203\n",
            "29it [02:49,  5.85s/it]\n",
            "8it [00:51,  6.04s/it][  8]     240 || B: 0.510 | C: 0.302 | M: 0.294 | S: 0.035 | T: 1.141 || ETA: 60 days, 2:17:29 || timer: 5.843\n",
            "18it [01:50,  6.11s/it][  8]     250 || B: 0.487 | C: 0.280 | M: 0.284 | S: 0.034 | T: 1.084 || ETA: 59 days, 21:05:11 || timer: 5.825\n",
            "28it [02:45,  5.35s/it][  8]     260 || B: 0.470 | C: 0.264 | M: 0.275 | S: 0.032 | T: 1.042 || ETA: 59 days, 11:55:27 || timer: 5.606\n",
            "29it [02:50,  5.88s/it]\n",
            "\n",
            "Computing validation mAP (this may take a while)...\n",
            "\n",
            "\n",
            "Calculating mAP...\n",
            "\n",
            "       |  all  |  .50  |  .55  |  .60  |  .65  |  .70  |  .75  |  .80  |  .85  |  .90  |  .95  |\n",
            "-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
            "   box | 10.86 | 15.94 | 15.77 | 15.42 | 14.72 | 14.08 | 13.41 | 11.41 |  6.69 |  1.19 |  0.01 |\n",
            "  mask | 13.44 | 16.45 | 16.14 | 16.13 | 15.93 | 15.40 | 14.71 | 14.27 | 13.62 | 10.13 |  1.67 |\n",
            "-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
            "\n",
            "9it [00:56,  5.68s/it][  9]     270 || B: 0.443 | C: 0.243 | M: 0.262 | S: 0.031 | T: 0.979 || ETA: 60 days, 2:42:07 || timer: 5.660\n",
            "19it [01:54,  5.70s/it][  9]     280 || B: 0.426 | C: 0.230 | M: 0.255 | S: 0.030 | T: 0.941 || ETA: 59 days, 21:00:53 || timer: 5.117\n",
            "29it [02:49,  5.86s/it]\n",
            "0it [00:00, ?it/s][ 10]     290 || B: 0.405 | C: 0.217 | M: 0.248 | S: 0.029 | T: 0.898 || ETA: 59 days, 17:22:12 || timer: 9.585\n",
            "10it [01:01,  5.85s/it][ 10]     300 || B: 0.391 | C: 0.206 | M: 0.243 | S: 0.028 | T: 0.867 || ETA: 59 days, 11:58:13 || timer: 4.910\n",
            "20it [01:59,  5.77s/it][ 10]     310 || B: 0.373 | C: 0.194 | M: 0.245 | S: 0.027 | T: 0.838 || ETA: 59 days, 7:05:37 || timer: 4.839\n",
            "29it [02:48,  5.81s/it]\n",
            "\n",
            "Computing validation mAP (this may take a while)...\n",
            "\n",
            "\n",
            "Calculating mAP...\n",
            "\n",
            "       |  all  |  .50  |  .55  |  .60  |  .65  |  .70  |  .75  |  .80  |  .85  |  .90  |  .95  |\n",
            "-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
            "   box | 12.83 | 16.64 | 16.46 | 16.44 | 16.08 | 15.75 | 15.07 | 14.55 | 11.32 |  5.55 |  0.40 |\n",
            "  mask | 15.42 | 16.30 | 16.30 | 16.30 | 16.30 | 16.30 | 16.10 | 15.89 | 15.54 | 14.68 | 10.44 |\n",
            "-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
            "\n",
            "1it [00:09,  9.54s/it][ 11]     320 || B: 0.351 | C: 0.183 | M: 0.244 | S: 0.026 | T: 0.804 || ETA: 59 days, 18:31:06 || timer: 5.888\n",
            "11it [01:07,  5.75s/it][ 11]     330 || B: 0.321 | C: 0.174 | M: 0.240 | S: 0.025 | T: 0.760 || ETA: 59 days, 14:38:19 || timer: 6.797\n",
            "21it [02:05,  5.63s/it][ 11]     340 || B: 0.311 | C: 0.167 | M: 0.239 | S: 0.024 | T: 0.741 || ETA: 59 days, 10:34:12 || timer: 6.515\n",
            "29it [02:48,  5.82s/it]\n",
            "2it [00:16,  7.74s/it][ 12]     350 || B: 0.304 | C: 0.163 | M: 0.236 | S: 0.023 | T: 0.726 || ETA: 59 days, 8:25:37 || timer: 7.583\n",
            "12it [01:16,  5.71s/it][ 12]     360 || B: 0.305 | C: 0.159 | M: 0.231 | S: 0.023 | T: 0.718 || ETA: 59 days, 5:20:41 || timer: 6.654\n",
            "16it [01:43,  6.49s/it]\n",
            "Stopping early. Saving network...\n"
          ]
        }
      ],
      "source": [
        "%cd /content/yolact-modified\n",
        "!rm -rf runs\n",
        "!activate yolact-env\n",
        "!python train.py --config=yolact_resnet50_bottle_config --batch_size=8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBeE9F4sPjur"
      },
      "source": [
        "#### Check Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, zipfile\n",
        "\n",
        "def folder_to_zip(folder, zip_file):\n",
        "    with zipfile.ZipFile(zip_file, 'w', zipfile.ZIP_DEFLATED) as zip_f:\n",
        "        for root, _, files in os.walk(folder):\n",
        "            for file in files:\n",
        "                zip_f.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), folder))\n",
        "\n",
        "folder_to_zip('/content/tests_results', '/content/tests_results.zip')\n",
        "print('Folder converted to ZIP successfully.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvH7SQBl7Jz5",
        "outputId": "4d7e81cf-ec9b-4239-f708-17bdfc36b2cd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder converted to ZIP successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jUI9HOnfmfsG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96efe9c3-1a30-46ff-db4f-9cb7142346b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/site-packages/torch/__init__.py:955: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:432.)\n",
            "  _C._set_default_tensor_type(t)\n",
            "/usr/local/lib/python3.10/site-packages/torch/jit/_recursive.py:314: UserWarning: 'downsample_layers' was found in ScriptModule constants,  but it is a non-constant submodule. Consider removing it.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/site-packages/torch/jit/_recursive.py:314: UserWarning: 'pred_layers' was found in ScriptModule constants,  but it is a non-constant submodule. Consider removing it.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/site-packages/torch/jit/_recursive.py:314: UserWarning: 'lat_layers' was found in ScriptModule constants,  but it is a non-constant submodule. Consider removing it.\n",
            "  warnings.warn(\n",
            "/content/yolact-modified/yolact.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(path)\n",
            "Loading model... Done.\n",
            "\n",
            "/content/tests/3077-3-0-2024-6-15-10-28-56-00x0011011010x111-1.jpg -> /content/tests_results/3077-3-0-2024-6-15-10-28-56-00x0011011010x111-1.png\n",
            "/content/tests/3076-9-0-2024-6-15-08-33-50-11x10x1x0x0x00011-1.jpg -> /content/tests_results/3076-9-0-2024-6-15-08-33-50-11x10x1x0x0x00011-1.png\n",
            "/content/tests/new-44.jpg -> /content/tests_results/new-44.png\n",
            "/content/tests/new-1.jpg -> /content/tests_results/new-1.png\n",
            "/content/tests/new-11.jpg -> /content/tests_results/new-11.png\n",
            "/content/tests/3077-3-1-2024-6-15-10-28-56-01x001x0100xxxx11-1.jpg -> /content/tests_results/3077-3-1-2024-6-15-10-28-56-01x001x0100xxxx11-1.png\n",
            "/content/tests/new-4.jpg -> /content/tests_results/new-4.png\n",
            "/content/tests/3077-7-0-2024-6-15-11-03-54-000000xx000000100-1.jpg -> /content/tests_results/3077-7-0-2024-6-15-11-03-54-000000xx000000100-1.png\n",
            "/content/tests/3077-4-0-2024-6-15-11-03-44-000x0x00x01xxx111-1.jpg -> /content/tests_results/3077-4-0-2024-6-15-11-03-44-000x0x00x01xxx111-1.png\n",
            "/content/tests/3076-5-1-2024-6-15-08-34-26-1xxx0x1x110x10x0x-1.jpg -> /content/tests_results/3076-5-1-2024-6-15-08-34-26-1xxx0x1x110x10x0x-1.png\n",
            "/content/tests/3076-10-1-2024-6-15-08-34-46-xx011111x11x0xx00-1.jpg -> /content/tests_results/3076-10-1-2024-6-15-08-34-46-xx011111x11x0xx00-1.png\n",
            "/content/tests/3076-5-0-2024-6-15-08-34-26-xx111101x01x11xx1-1.jpg -> /content/tests_results/3076-5-0-2024-6-15-08-34-26-xx111101x01x11xx1-1.png\n",
            "/content/tests/3076-9-1-2024-6-15-08-35-24-0000x110x00x10x0x-1.jpg -> /content/tests_results/3076-9-1-2024-6-15-08-35-24-0000x110x00x10x0x-1.png\n",
            "/content/tests/3077-4-1-2024-6-15-11-05-10-010x1000001x11xxx-1.jpg -> /content/tests_results/3077-4-1-2024-6-15-11-05-10-010x1000001x11xxx-1.png\n",
            "/content/tests/new-2.jpg -> /content/tests_results/new-2.png\n",
            "/content/tests/new-3.jpg -> /content/tests_results/new-3.png\n",
            "/content/tests/3076-9-1-2024-6-15-08-35-56-1x10111110x100101-1.jpg -> /content/tests_results/3076-9-1-2024-6-15-08-35-56-1x10111110x100101-1.png\n",
            "/content/tests/new-22.jpg -> /content/tests_results/new-22.png\n",
            "/content/tests/3077-1-1-2024-6-15-10-29-42-x01x000000x1x0xx1-1.jpg -> /content/tests_results/3077-1-1-2024-6-15-10-29-42-x01x000000x1x0xx1-1.png\n",
            "/content/tests/3076-4-0-2024-6-15-08-34-10-xxx0x011x0x0x1x1x-1.jpg -> /content/tests_results/3076-4-0-2024-6-15-08-34-10-xxx0x011x0x0x1x1x-1.png\n",
            "/content/tests/2.jpg -> /content/tests_results/2.png\n",
            "/content/tests/3077-5-0-2024-6-15-10-28-42-10x10xx00xx10110x-1.jpg -> /content/tests_results/3077-5-0-2024-6-15-10-28-42-10x10xx00xx10110x-1.png\n",
            "/content/tests/3077-3-1-2024-6-15-10-29-51-x0xxxxxx100x10001-1.jpg -> /content/tests_results/3077-3-1-2024-6-15-10-29-51-x0xxxxxx100x10001-1.png\n",
            "/content/tests/3076-6-0-2024-6-15-08-34-59-1x0x1x00x00010001-1.jpg -> /content/tests_results/3076-6-0-2024-6-15-08-34-59-1x0x1x00x00010001-1.png\n",
            "/content/tests/3076-10-0-2024-6-15-08-35-41-x0x00xxx11xx1xxx0-1.jpg -> /content/tests_results/3076-10-0-2024-6-15-08-35-41-x0x00xxx11xx1xxx0-1.png\n",
            "/content/tests/3077-3-1-2024-6-15-11-04-45-001100xx1010xxx10-1.jpg -> /content/tests_results/3077-3-1-2024-6-15-11-04-45-001100xx1010xxx10-1.png\n",
            "/content/tests/4.jpg -> /content/tests_results/4.png\n",
            "/content/tests/new-33.jpg -> /content/tests_results/new-33.png\n",
            "/content/tests/3.jpg -> /content/tests_results/3.png\n",
            "/content/tests/3077-7-0-2024-6-15-11-04-17-xx001000xx000111x-1.jpg -> /content/tests_results/3077-7-0-2024-6-15-11-04-17-xx001000xx000111x-1.png\n",
            "/content/tests/3077-2-1-2024-6-15-11-04-05-x10001100011x10x1-1.jpg -> /content/tests_results/3077-2-1-2024-6-15-11-04-05-x10001100011x10x1-1.png\n",
            "/content/tests/3077-1-1-2024-6-15-11-03-33-0x01xxxxx1xx011x0-1.jpg -> /content/tests_results/3077-1-1-2024-6-15-11-03-33-0x01xxxxx1xx011x0-1.png\n",
            "/content/tests/1.jpg -> /content/tests_results/1.png\n",
            "/content/tests/3076-1-1-2024-6-15-08-33-59-100x01xx01001x11x-1.jpg -> /content/tests_results/3076-1-1-2024-6-15-08-33-59-100x01xx01001x11x-1.png\n",
            "/content/tests/3076-1-1-2024-6-15-08-33-36-x1010xx10xx001x11-1.jpg -> /content/tests_results/3076-1-1-2024-6-15-08-33-36-x1010xx10xx001x11-1.png\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "!python eval.py --trained_model=/content/yolact-modified/weights/bottle_detection_12_364_interrupt.pth --config=yolact_resnet50_bottle_config --score_threshold=0.3 --top_k=15 --images=/content/tests:/content/tests_results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "def unzip(zip_file, extract_to):\n",
        "    with zipfile.ZipFile(zip_file) as zip_f:\n",
        "        zip_f.extractall(extract_to)\n",
        "\n",
        "unzip('/content/tests.zip', '/content/tests')\n",
        "print('File extracted successfully.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmfQ9GqCDryc",
        "outputId": "375b3a5d-6c59-4dd9-fecf-f101657ac486"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File extracted successfully.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}